{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c41983",
   "metadata": {},
   "source": [
    "# Offline on the Feed Forward Neural Network\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Each layers implementation can be found in the `layers.py` file. The `network.py` file contains the implementation of the network. The forward pass and backward pass is implemented here. The same file contains the training code also predict function which is used to predict the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd52432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torchvision.datasets as ds\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "train_validation_set = ds.EMNIST(root='./data', \n",
    "                                split='letters',\n",
    "                                train=True,\n",
    "                                transform=transforms.ToTensor(),\n",
    "                                download=True)\n",
    "\n",
    "train_validation_data =[]\n",
    "train_validation_labels = []\n",
    "\n",
    "for data, label in train_validation_set:\n",
    "    data_flatten = data.view(-1)\n",
    "    train_validation_data.append(data_flatten.numpy())\n",
    "    train_validation_labels.append(label)\n",
    "    \n",
    "train_validation_data = np.array(train_validation_data)\n",
    "train_validation_labels = np.array(train_validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print the number of samples in the training set\n",
    "print(\"Number of samples in the training set: \", len(train_validation_data))\n",
    "\n",
    "# print the shape of each sample\n",
    "print(\"Shape of each sample: \", train_validation_data.shape)\n",
    "\n",
    "# print the shape of the labels\n",
    "print(\"Shape of labels: \", train_validation_labels.shape)\n",
    "\n",
    "# reshape the labels to be a column vector\n",
    "train_validation_labels = train_validation_labels.reshape(-1, 1)\n",
    "\n",
    "# print the shape of the labels\n",
    "print(\"Shape of labels: \", train_validation_labels.shape)\n",
    "\n",
    "# print the number of different labels in the training set\n",
    "print(\"Number of different labels: \", len(np.unique(train_validation_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5999f96",
   "metadata": {},
   "source": [
    "### Plot the first 5 images in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the first 5 samples in the training set\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i+1)\n",
    "    ax.imshow(train_validation_data[i].reshape(28, 28), cmap='gray')\n",
    "    ax.set_title(\"Label: {}\".format(train_validation_labels[i]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f78d85",
   "metadata": {},
   "source": [
    "### One hot encoding of labels\n",
    " \n",
    "We want to convert the labels into one hot encoding. The one hot encoding is a vector of length equal to the number of classes. \n",
    "The vector is all zeros except for the class which is represented by a one. For example, \n",
    "- if the class is 3 and the total number of classes is 5 then the one hot encoding will be `[0, 0, 0, 1, 0]`. The one hot encoding of the labels is stored in the variable `y_oh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# create the one hot encoder\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "\n",
    "# fit the encoder to the labels\n",
    "one_hot_encoder.fit(train_validation_labels)\n",
    "\n",
    "# transform the labels using the one hot encoder\n",
    "train_validation_labels = one_hot_encoder.transform(train_validation_labels).toarray()\n",
    "\n",
    "# print the shape of the labels\n",
    "print(\"Shape of labels: \", train_validation_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a67159",
   "metadata": {},
   "source": [
    "\n",
    "### Create the network with the following architecture\n",
    "\n",
    "- Input layer with 784 neurons\n",
    "- Hidden layer with 256 neurons\n",
    "- Output layer with 26 neurons\n",
    "- Activation function for hidden layer: ReLU\n",
    "- Number of hidden layers: 2\n",
    "- Number of epochs: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dfba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from network import Network\n",
    "from loss import categorical_cross_entropy, categorical_cross_entropy_prime\n",
    "from activation import SigmoidActivation\n",
    "from dense_layer import DenseLayer\n",
    "from dropout_layer import DropoutLayer\n",
    "\n",
    "layers = [\n",
    "    DenseLayer(784, 256),\n",
    "    SigmoidActivation(),\n",
    "    DropoutLayer(0.2),\n",
    "    DenseLayer(256, 128),\n",
    "    SigmoidActivation(),\n",
    "    DropoutLayer(0.2),\n",
    "    DenseLayer(128, 26),\n",
    "]\n",
    "\n",
    "# create a network object\n",
    "# net = Network(number_of_inputs=784,\n",
    "#               number_of_outputs=26,\n",
    "#               number_of_layers=3,\n",
    "#               number_of_nodes_in_dense_layer=256,\n",
    "#               epochs=100,\n",
    "#               verbose=True,\n",
    "#               learning_rate=0.0005,\n",
    "#               decay_rate=0.99995,\n",
    "#               activation_class=SigmoidActivation,\n",
    "#               loss_function=categorical_cross_entropy,\n",
    "#               loss_function_prime=categorical_cross_entropy_prime,)\n",
    "net = Network(layers=layers,\n",
    "                epochs=100,\n",
    "                verbose=True,\n",
    "                learning_rate=0.0005,\n",
    "                decay_rate=0.99995,\n",
    "                loss_function=categorical_cross_entropy,\n",
    "                loss_function_prime=categorical_cross_entropy_prime,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3d6c8",
   "metadata": {},
   "source": [
    "### Train and test split of the dataset\n",
    "\n",
    "The dataset is split into training and testing dataset. The training dataset is used to train the network and the testing dataset is used to test the network. The training dataset is 80% of the total dataset and the testing dataset is 20% of the total dataset. The training dataset is stored in the variables `X_train` and `y_train`. The testing dataset is stored in the variables `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the training set into training and validation sets\n",
    "train_data, validation_data, train_labels, validation_labels = train_test_split(train_validation_data, \n",
    "                                                                                train_validation_labels, \n",
    "                                                                                test_size=0.15, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# check the shape of the training data\n",
    "print(\"Shape of training data: \", train_data.shape)\n",
    "print(\"Shape of training labels: \", train_labels.shape)\n",
    "\n",
    "# check the shape of the validation data\n",
    "print(\"Shape of validation data: \", validation_data.shape)\n",
    "print(\"Shape of validation labels: \", validation_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb20299",
   "metadata": {},
   "source": [
    "### Train the network\n",
    "\n",
    "We can train the network by calling the `train` function. The `train` function takes the following parameters:\n",
    "\n",
    "- `X`: Training data\n",
    "- `Y`: Training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05848769",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# train the network\n",
    "net.train(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281c6e3",
   "metadata": {},
   "source": [
    "### Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829cb82",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3)\n",
    "\n",
    "# plot the loss curve\n",
    "axs[0].plot(range(net.epochs), net.losses)\n",
    "axs[0].set(xlabel=\"Epoch\", ylabel=\"Loss\")\n",
    "\n",
    "# plot the accuracy curve\n",
    "axs[1].plot(range(net.epochs), net.accuracy)\n",
    "axs[1].set(xlabel=\"Epoch\", ylabel=\"Accuracy\")\n",
    "\n",
    "# plot the macro f1 score curve\n",
    "axs[2].plot(range(net.epochs), net.f1_score)\n",
    "axs[2].set(xlabel=\"Epoch\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0794ad",
   "metadata": {},
   "source": [
    "### Predict the output of the network\n",
    "\n",
    "We can predict the output of the network by calling the `predict` function.\n",
    "\n",
    "\n",
    "We will also calculate the validation loss, validation accuracy and validation macro-f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network on the validation set\n",
    "\n",
    "model_prediction = net.predict(validation_data)\n",
    "\n",
    "validation_loss = np.mean(net.loss_function(validation_labels, model_prediction)) / len(validation_labels)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# calculate the accuracy of the model\n",
    "val_accuracy_score = accuracy_score(validation_labels.argmax(axis=1), model_prediction.argmax(axis=1))\n",
    "\n",
    "# calculate the f1 score of the model\n",
    "val_f1_score = f1_score(validation_labels.argmax(axis=1), model_prediction.argmax(axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fde2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print the loss of the model\n",
    "print(\"Validation Loss of the model: \", validation_loss)\n",
    "\n",
    "# print the accuracy of the model\n",
    "print(\"Validation Accuracy of the model: \", val_accuracy_score)\n",
    "\n",
    "# print the f1 score of the model\n",
    "print(\"Validation macro-F1 score of the model: \", val_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a994ab4",
   "metadata": {},
   "source": [
    "### Calculate the training loss, training accuracy and training macro-f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a909b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict training data\n",
    "model_prediction = net.predict(train_data)\n",
    "\n",
    "# calculate the loss on the training data\n",
    "train_loss = np.mean(net.loss_function(train_labels, model_prediction)) / len(train_labels)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "train_accuracy_score = accuracy_score(train_labels.argmax(axis=1), model_prediction.argmax(axis=1))\n",
    "\n",
    "# calculate the f1 score of the model\n",
    "train_f1_score = f1_score(train_labels.argmax(axis=1), model_prediction.argmax(axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809341d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the loss of the model\n",
    "print(\"Training Loss of the model: \", train_loss)\n",
    "\n",
    "# print the accuracy of the model\n",
    "print(\"Training Accuracy of the model: \", train_accuracy_score)\n",
    "\n",
    "# print the f1 score of the model\n",
    "print(\"Training macro-F1 score of the model: \", train_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafea080",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "We will use the `pickle` library to save the model. The model is saved in the file `model_1805086.pkl`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
